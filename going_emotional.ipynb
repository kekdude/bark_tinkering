{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd653e6-52d6-4235-94a2-840920e7e149",
   "metadata": {},
   "source": [
    "# Going emotional\n",
    "\n",
    "Sometimes Bark understands emotions from the text by itself.\n",
    "\n",
    "We can use that and create speaker from generation to capture the emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea6e1bd-5cf5-4349-802c-4567882769a3",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080eb4f-e375-4cc3-a35f-37676cec189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from optimum.bettertransformer import BetterTransformer\n",
    "from transformers import BarkProcessor, BarkModel\n",
    "from bark_tinkering.adversarial_speaker import find_semantics_by_wav, \\\n",
    "    create_voice_preset, save_voice_preset_safetensors, load_voice_preset_safetensors, load_voice_preset_numpy, \\\n",
    "    create_voice_preset_from_generation\n",
    "from bark_tinkering.utils import bark_generate\n",
    "import IPython\n",
    "from notebook_utils import display_generation_result\n",
    "\n",
    "device = 'cuda'\n",
    "transformers_cache_dir = '.cache'\n",
    "model_id = 'suno/bark'\n",
    "\n",
    "processor: BarkProcessor = BarkProcessor.from_pretrained(model_id, cache_dir=transformers_cache_dir)\n",
    "\n",
    "# Load model in float16\n",
    "model: BarkModel = BarkModel.from_pretrained(model_id, cache_dir=transformers_cache_dir, torch_dtype=torch.float16).to(device)\n",
    "\n",
    "# Convert model to BetterTransformer\n",
    "model = BetterTransformer.transform(model, keep_original_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64b27a-a2c4-4240-9686-64bbd2bc1ca3",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7d24c-35df-4c6e-bad8-c512b5a3abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_voice_preset = load_voice_preset_safetensors('voice_presets/lina.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2896001d-0705-41d9-8a36-b1ab9d31ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_neutral_voicelines(voice_preset):\n",
    "    text_prompt = [\"Does that mean what I think it means?\", \n",
    "               \"Who ordered a pizza?\", \n",
    "               \"It suits you.\"]\n",
    "    inputs = processor(text_prompt, voice_preset=voice_preset).to(device)\n",
    "    torch.manual_seed(0)\n",
    "    with torch.inference_mode():\n",
    "        generations = bark_generate(model, **inputs, min_eos_p=0.05, return_output_lengths=True)\n",
    "        display_generation_result(generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890417e-89dd-416f-9314-83159a56ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_neutral_voicelines(original_voice_preset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ddf2a7-3323-4c4a-93bd-91b6804d4def",
   "metadata": {},
   "source": [
    "## Generate angry voicelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbaf37-7a28-475d-8f09-e553d3f7d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_angry_voicelines(voice_preset):\n",
    "    text_prompt = [\"I'm so furious right now, I could spit nails!\",\n",
    "              \"Someone's gonna pay for this! This is freaking ridiculous!\",\n",
    "              \"I want to rip someone's head off!\",\n",
    "              \"This is beyond frustrating!\",\n",
    "              \"You have got to be kidding me...\"]\n",
    "    inputs = processor(text_prompt, voice_preset=voice_preset).to(device)\n",
    "    torch.manual_seed(4)\n",
    "    with torch.inference_mode():\n",
    "        generations = bark_generate(model, **inputs, min_eos_p=0.05, return_output_lengths=True)\n",
    "        display_generation_result(generations)\n",
    "        return generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6e080-af3d-498e-b3e9-4ae89cc096f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_generations = generate_angry_voicelines(original_voice_preset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff324fc-cb03-45ee-be90-05d032ff0014",
   "metadata": {},
   "source": [
    "### Ok, sounds bit angry. Let's make a speaker from this generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0999fe9-6ef1-4aa0-b79f-3fbcb28c080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_generation_result(angry_generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e6543-95f5-47ba-97cf-a3bd0d93afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "angry_voice_preset = create_voice_preset_from_generation(angry_generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a6685-bc8d-478a-b946-7719fccc7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_neutral_voicelines(angry_voice_preset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a77375-839b-497a-b7f8-f2f9ead5c90b",
   "metadata": {},
   "source": [
    "It changed a bit, but can't say Lina is really furious. Also seems like a pizza makes everything better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c03b22-de2b-423f-ae58-b462df226991",
   "metadata": {},
   "source": [
    "### Use angry speaker to generate even angrier voicelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da089e0-800d-4b50-842e-71009a7d5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "furious_generations = generate_angry_voicelines(angry_voice_preset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64592c78-8733-4da9-aa6b-d6a93a8f060f",
   "metadata": {},
   "source": [
    "Oooh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a799d-293b-4db3-8693-92ec59c76c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_generation_result(furious_generations[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0584c7d-6f58-4287-9674-2a5d18b5d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "furious_voice_preset = create_voice_preset_from_generation(furious_generations[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b5c836-4631-42ea-84f7-30730a5b164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_neutral_voicelines(furious_voice_preset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb404b5-863a-47be-bc08-93e651aca289",
   "metadata": {},
   "source": [
    "Well, now it is dangerous. Let's save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f61db-e8a3-43c7-ba66-432c037f25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_voice_preset_safetensors(angry_voice_preset, 'voice_presets/lina_angry.safetensors')\n",
    "save_voice_preset_safetensors(furious_voice_preset, 'voice_presets/lina_furious.safetensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f9c691-fb04-4942-8741-97ef15731e50",
   "metadata": {},
   "source": [
    "As you've noticed, some generations are very noisy to say at least. It happens even without a speaker. But it seems creating speaker out of speaker makes it worse, so generate more and choose clean generations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
