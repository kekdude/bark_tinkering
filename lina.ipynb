{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "563817c2-8630-4e6b-8043-cdd896c9dade",
   "metadata": {},
   "source": [
    "# Create adversarial speaker\n",
    "\n",
    "1. Use audio file and transcription to find corresponding semantics\n",
    "2. Use this semantics to construct \"first order\" speaker and make some generations\n",
    "3. Choose good generation to create \"second order\" speaker from it\n",
    "4. Save speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b7826-7918-47fd-82dc-583143e08cde",
   "metadata": {},
   "source": [
    "### Import stuff and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1f0dc-5b75-400a-974e-f9e061215c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BarkProcessor, BarkModel\n",
    "from bark_tinkering.adversarial_speaker import find_semantics_by_wav, \\\n",
    "    create_voice_preset, save_voice_preset_safetensors, load_voice_preset_safetensors, load_voice_preset_numpy\n",
    "from bark_tinkering.utils import make_text_generations\n",
    "import IPython\n",
    "\n",
    "device = 'cuda'\n",
    "transformers_cache_dir = '.cache'\n",
    "model_id = 'suno/bark' # use 'suno/bark-small' if you don't have enough memory, but generations will differ\n",
    "\n",
    "processor: BarkProcessor = BarkProcessor.from_pretrained(model_id, cache_dir=transformers_cache_dir)\n",
    "model: BarkModel = BarkModel.from_pretrained(model_id, cache_dir=transformers_cache_dir).to(device)\n",
    "\n",
    "# default temperature is 0.7, I want model to be more conservative\n",
    "model.generation_config.semantic_config['temperature'] = 1.0\n",
    "model.generation_config.coarse_acoustics_config['temperature'] = 1.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194e639-6194-42ef-92b1-3d5a5f22e732",
   "metadata": {},
   "source": [
    "## 1. Find adversarial semantic for audio sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac1c91-d6a1-4d2b-aaa7-70d602d8f24f",
   "metadata": {},
   "source": [
    "**You can skip running following cell if you just want to see outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd90a53-9692-48a3-a586-10eca25268cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(952933090653967155) # fixing seed to make this reproducable\n",
    "find_semantics_by_wav(model, processor, \"One little spark and before you know it, the whole world is burning.\",\n",
    "                      './character_samples/lina.wav',\n",
    "                      './generations/lina',\n",
    "                      lr=1e-1,\n",
    "                      save_every_n_steps=100,\n",
    "                      no_save_steps=999,\n",
    "                      steps=2000,\n",
    "                      device=device,\n",
    "                      perplexity_loss_weight=0.02) # 0.02 to 0.2 usually ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06832ced-c6c6-4f75-9189-c4981d773cd4",
   "metadata": {},
   "source": [
    "### Check generations on different steps. They should become icncreasingly close to source audio sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc7682-fff3-407f-b6bc-803f491848fc",
   "metadata": {},
   "source": [
    "You can either do it from here or open generations/lina/all.m3u in your audio player. Usually somewhere around 1500-2000 steps should be a good generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ed242-96bf-48ed-8ff8-43b412de2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(1000, 2001, 100):\n",
    "    print(f'step {step}')\n",
    "    IPython.display.display(IPython.display.Audio(f'generations/lina/step_{step}/audio.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76913c8b-92cd-4cf6-bb33-5ad9ec5704cb",
   "metadata": {},
   "source": [
    "I like generation on step 1900, let's make a speaker out of it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8891285-6399-4601-a278-3f8a54bdd454",
   "metadata": {},
   "source": [
    "## 2. Create first order speaker and make some generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da73b64c-8fda-43ee-87db-86a6fe275a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(952933090653967155)\n",
    "voice_preset = create_voice_preset(\n",
    "    model,\n",
    "    'character_samples/lina.wav', # original audio sample\n",
    "    'generations/lina/step_1900/semantic.pt' # semantic we found on step 1900\n",
    ")\n",
    "make_text_generations(model, processor, [\"There are a lot of things I could talk about, but it would probably sound similar to this.\"] * 10,\n",
    "                      f'generations/lina_first_order_speaker_1900',\n",
    "                      voice_preset=voice_preset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79efd0ad-f17b-4c57-b65a-5acf159c9e8d",
   "metadata": {},
   "source": [
    "Check the generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75556c8-8553-407c-b923-7e88356ec772",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen in range(10):\n",
    "    print(f'gen {gen}')\n",
    "    IPython.display.display(IPython.display.Audio(f'generations/lina_first_order_speaker_1900/{gen}/audio.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32336a4c-ad0a-4946-9def-fa0e62f2ac96",
   "metadata": {},
   "source": [
    "Let's take generation 8 and make second order speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3844a70e-e429-4c7c-8a81-5718855a57aa",
   "metadata": {},
   "source": [
    "## 3. Create second order speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b2634-320d-4e5a-b311-c7acdaf9c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(952933090653967155)\n",
    "voice_preset = create_voice_preset(\n",
    "    model,\n",
    "    'generations/lina_first_order_speaker_1900/8/audio.wav',\n",
    "    'generations/lina_first_order_speaker_1900/8/semantic.pt'\n",
    ")\n",
    "make_text_generations(model, processor, [\"This is one bridge I don't mind burning.\"] * 10,\n",
    "                      f'generations/lina_second_order_speaker_8',\n",
    "                      voice_preset=voice_preset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ae1ac-e0e0-462a-8be5-d8f730c4a149",
   "metadata": {},
   "source": [
    "Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e957f8-9afd-499f-8fed-f782fe59b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen in range(10):\n",
    "    print(f'gen {gen}')\n",
    "    IPython.display.display(IPython.display.Audio(f'generations/lina_second_order_speaker_8/{gen}/audio.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621676a-d594-422a-b99e-70478567711c",
   "metadata": {},
   "source": [
    "## 4. Save speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad962b5-cebc-4535-9c77-342e8e0ce787",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_preset = create_voice_preset(\n",
    "    model,\n",
    "    'generations/lina_first_order_speaker_1900/8/audio.wav',\n",
    "    'generations/lina_first_order_speaker_1900/8/semantic.pt'\n",
    ")\n",
    "save_voice_preset_safetensors(voice_preset, 'voice_presets/lina.safetensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac34d59-7936-470f-920c-64c4673ee9a2",
   "metadata": {},
   "source": [
    "## Load speaker and make some generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c23c17-c74f-42b1-9c4a-e25b274a8362",
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_preset = load_voice_preset_safetensors('voice_presets/lina.safetensors')\n",
    "\n",
    "torch.manual_seed(952933090653967155)\n",
    "make_text_generations(model, processor, [\"Hey, look at you, you got there!\"],\n",
    "                      f'generations/lina_temp',\n",
    "                      voice_preset=voice_preset)\n",
    "\n",
    "IPython.display.Audio(f'generations/lina_temp/0/audio.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
